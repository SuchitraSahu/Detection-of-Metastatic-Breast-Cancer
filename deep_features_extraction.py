# -*- coding: utf-8 -*-
"""Deep Features Extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dt3C8_sSY2IXlPgi64795eHmbZqS-8xH
"""

from google.colab import drive
drive.mount('/gdrive')

"""Loading data + Pre processing"""

!pip install -q tensorflow

import tensorflow
import numpy as np
import keras
from tensorflow import keras
import tensorflow.keras
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
from tensorflow.keras.applications import imagenet_utils
from IPython.display import Image
import os

# for images
# from tensorflow.keras.preprocessing import image
# import numpy as np
# import os

imgs_train = []
label_train = []  # Instead of list(), you can use []
directory = '/gdrive/MyDrive/Breast Cancer DataSET/roi/10'  # Make sure this is the correct directory path

for img_name in os.listdir(directory):
    img_path = os.path.join(directory, img_name)
    print("Processing:", img_path)
    imgs_train.append(img_path)
    label_train.append(0)

temp_data=np.array([imgs_train, label_train])
temp_data = np.transpose(temp_data)
np.random.shuffle(temp_data)
image_list = temp_data[:,0]
label_list = temp_data[:,1]
label_list = [int(i) for i in label_list]
# filename = '/content/image_177.png'
# img = image.load_img(filename,target_size=(224,224))
# resizedimg = image.img_to_array(img)
# finalimg = np.expand_dims(resizedimg,axis=0)

"""RESNET FINE-TUNED ON OUR DATASET"""

from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import layers

# Load pre-trained ResNet50 with top layers included
base_model = ResNet50(weights='imagenet', include_top=False)

# Add custom top layers for classification on top of the base ResNet model
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)  # Add new fully connected layer
predictions = Dense(2, activation='softmax')(x)  # Adjust NUM_CLASSES based on your dataset

# Create the model by combining base ResNet model and new dense layers
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze pre-trained layers in the base ResNet model (optional)
for layer in base_model.layers:
    layer.trainable = False

# Compile the model with the updated learning_rate parameter
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Assuming you have prepared your dataset using ImageDataGenerator

# Training data preparation
# image_list = ['/path/to/image1.jpg', '/path/to/image2.jpg', ...]  # Replace with your image paths

training_data = []
label_list = []  # Assuming you have a binary classification problem

for image_path in image_list:
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    training_data.append(img_array)
    label_list.append([0, 0])  # Set label to [0, 0] for each image

# Convert lists to numpy arrays
training_data = np.vstack(training_data)
label_list = np.array(label_list)

# Train the model
model.fit(training_data, label_list, epochs=5)  # Adjust epochs as needed

# Extract features using the fine-tuned model
#feature_extractor = Model(inputs=model.input, outputs=model.get_layer('global_average_pooling2d').output) #########
feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)
#############################          CHANGE            ##############################

# Extract features from your dataset images
features = []

for image_path in image_list:
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    features.append(feature_extractor.predict(img_array))

# 'features' now contains the extracted features from your dataset images using the fine-tuned ResNet50 model

print(len(image_list))

from tensorflow.python.keras.layers import Dense

from tensorflow.keras.applications import ResNet50, VGG16, MobileNetV2
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D

# Load ResNet50, VGG16, and MobileNetV2 without the fully connected layers
resnet_model = ResNet50(weights='imagenet', include_top=False)
vgg16_model = VGG16(weights='imagenet', include_top=False)
mobilenet_model = MobileNetV2(weights='imagenet', include_top=False)

# Add Global Average Pooling layers to each model
resnet_gap_output = GlobalAveragePooling2D()(resnet_model.output)
vgg16_gap_output = GlobalAveragePooling2D()(vgg16_model.output)
mobilenet_gap_output = GlobalAveragePooling2D()(mobilenet_model.output)

# Create models that output features after Global Average Pooling
resnet_gap_feature_model = Model(inputs=resnet_model.input, outputs=resnet_gap_output)
vgg16_gap_feature_model = Model(inputs=vgg16_model.input, outputs=vgg16_gap_output)
mobilenet_gap_feature_model = Model(inputs=mobilenet_model.input, outputs=mobilenet_gap_output)

# List to store extracted features after Global Average Pooling
resnet_gap_features = []
vgg16_gap_features = []
mobilenet_gap_features = []

# Loop through images
for img_path in image_list:  # Assuming image_paths contains paths to your images
    img = tensorflow.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))
    img_array = tensorflow.keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)

    # Preprocess the image based on the model
    resnet_processed_img = resnet_preprocess(img_array)
    vgg16_processed_img = vgg_preprocess(img_array)
    mobilenet_processed_img = mobilenet_preprocess(img_array)

    # Extract features using Global Average Pooling for each model
    resnet_gap_img_features = resnet_gap_feature_model.predict(resnet_processed_img)
    vgg16_gap_img_features = vgg16_gap_feature_model.predict(vgg16_processed_img)
    mobilenet_gap_img_features = mobilenet_gap_feature_model.predict(mobilenet_processed_img)

    # Append extracted features to the respective lists
    resnet_gap_features.append(resnet_gap_img_features)
    vgg16_gap_features.append(vgg16_gap_img_features)
    mobilenet_gap_features.append(mobilenet_gap_img_features)

# 'resnet_gap_features', 'vgg16_gap_features', 'mobilenet_gap_features' contain the GAP features for each model

vgg_gap_final = np.array(vgg16_gap_features)
vgg_gap_final = np.reshape(vgg_gap_final, (len(image_list), 512))

vgg_gap_final

import numpy as np
import pandas as pd
from google.colab import files

# Assuming 'vgg_gap_final.csv' is the desired file name
pd.DataFrame(vgg_gap_final).to_csv('/gdrive/MyDrive/Breast Cancer DataSET/Deep Features/vgg/vgg_gap_final_10_0.csv', index=False)

# Download the file
#files.download('/gdrive/MyDrive/Breast Cancer DataSET/Deep Features/vgg/vgg_gap_final_10_0.csv')

resnet_gap_final = np.array(resnet_gap_features)
resnet_gap_final = np.reshape(resnet_gap_final, (len(image_list), 2048))
#resnet_gap_final = np.reshape(resnet_gap_final, (len(image_list), 512))

###################################     CHANGE     ########################################

resnet_gap_final

import numpy as np
import pandas as pd
from google.colab import files

# Assuming 'vgg_gap_final.csv' is the desired file name
pd.DataFrame(vgg_gap_final).to_csv('/gdrive/MyDrive/Breast Cancer DataSET/Deep Features/resnet_gap/resnet_gap_final_10_0.csv', index=False)

# Download the file
#files.download('/gdrive/MyDrive/Breast Cancer DataSET/Deep Features/resnet_gap/resnet_gap_final_23_0.csv')

# print(mobilenet_deep_features.size())
import pandas as pd
mobilenet_gap_final = np.array(mobilenet_gap_features)
mobilenet_gap_final = np.reshape(mobilenet_gap_final, (len(image_list), 1280))
# mobilenet_gap_final = np.reshape(mobilenet_gap_final, (len(image_list), 512))

#####################################   CHANGE  ########################################

mobilenet_gap_final

import numpy as np
import pandas as pd
from google.colab import files

# Assuming 'vgg_gap_final.csv' is the desired file name
pd.DataFrame(vgg_gap_final).to_csv('/gdrive/MyDrive/Breast Cancer DataSET/Deep Features/mobilenet_gap/mobilenet_gap_final_10_0.csv', index=False)

# Download the file
#files.download('/gdrive/MyDrive/Breast Cancer DataSET/Deep Features/mobilenet_gap/mobilenet_gap_final_23_0.csv')

print(mobilenet_gap_img_features.shape)
print(resnet_gap_img_features.shape)
print(vgg16_gap_img_features.shape)

import numpy as np
import pandas as pd

# Assuming 'vgg_gap_final.csv' is the desired file name
file_path = '/gdrive/MyDrive/Breast Cancer DataSET/Deep Features/resnet_gap/resnet_gap_final_10.csv'
pd.DataFrame(resnet_gap_final).to_csv(file_path, index=False)

file_path = '/gdrive/MyDrive/Breast Cancer DataSET/Deep Features/mobilenet_gap/mobilenet_gap_final_10.csv'
pd.DataFrame(mobilenet_gap_final).to_csv(file_path, index=False)

file_path = '/gdrive/MyDrive/Breast Cancer DataSET/Deep Features/vgg/vgg_gap_final_10.csv'
pd.DataFrame(vgg_gap_final).to_csv(file_path, index=False)